{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, boto3, logging, sys, datetime\n",
    "from farmhash import FarmHash32 as fhash\n",
    "from botocore.exceptions import ClientError\n",
    "import pandas as pd\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 client 생성에 필요한 보안 자격 증명 정보 get\n",
    "with open(\"../../.KEYS/FIRST_PREPROCESSING_KEY.json\", \"r\") as f:\n",
    "    aws_key = json.load(f)\n",
    "\n",
    "# S3 버킷 정보 get\n",
    "with open(\"../../.KEYS/DATA_SRC_INFO.json\", \"r\") as f:\n",
    "    storage_info = json.load(f)\n",
    "    \n",
    "# S3 섹션 및 client 생성\n",
    "session = boto3.Session(\n",
    "    aws_access_key_id=aws_key['aws_access_key_id'],\n",
    "    aws_secret_access_key=aws_key['aws_secret_key'],\n",
    "    region_name=aws_key['region']\n",
    ")\n",
    "\n",
    "# S3 버킷 정보 init\n",
    "s3 = session.client('s3')\n",
    "pull_bucket_name = storage_info['pull_bucket_name']\n",
    "push_table_name = storage_info['restore_table_name']\n",
    "data_archive_bucket_name = storage_info['crawl_data_bucket_name']\n",
    "id_list_bucket_name = storage_info['id_storage_bucket_name']\n",
    "target_folder_prefix = storage_info['target_folder_prefix']['wanted_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id_from_s3(s3_client, buket_name, prefix):\n",
    "    metadata_list = utils.get_bucket_metadata(s3_client, buket_name,prefix)\n",
    "    if len(metadata_list) > 1:\n",
    "        try:\n",
    "            _obj = metadata_list[1]\n",
    "            response = s3.get_object(Bucket=buket_name, Key=_obj['Key'])\n",
    "            json_context = response['Body'].read().decode('utf-8')\n",
    "            join_dict = json.loads(json_context)\n",
    "            return join_dict.get('ids')\n",
    "        except json.JSONDecodeError as e:\n",
    "            logging.error(f\"JSONDecodeError encountered: {e}\")\n",
    "            return False\n",
    "        except ClientError as e:\n",
    "            logging.error(f\"ClientError encountered: {e}\")\n",
    "            return False\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Unknow Error. encountered: {e}\")\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_id_to_s3(s3_client, buket_name, prefix, upload_id_list):\n",
    "    odd_id_list = get_id_from_s3(s3_client, buket_name, \"obj_ids.json\")\n",
    "    new_id_list = list(set(odd_id_list + upload_id_list))\n",
    "    update_date = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
    "    data = {\n",
    "        \"version\": \"2024-09-04\",\n",
    "        \"statement\": \"id_list_of_precessed_data_objects\",\n",
    "        \"ids\": new_id_list,\n",
    "        \"last_update\": update_date\n",
    "    }\n",
    "    json_string = json.dumps(data)\n",
    "    response = s3_client.put_object(\n",
    "        Bucket=buket_name,          # 버킷 이름\n",
    "        Key=prefix,             # 업로드할 파일의 키(경로 및 이름)\n",
    "        Body=json_string,               # 업로드할 파일의 내용\n",
    "        ContentType='application/json'  # 파일의 MIME 타입\n",
    "    )\n",
    "    \n",
    "    return response\n",
    "    \n",
    "def get_id_from_s3(s3_client, buket_name, prefix):\n",
    "    metadata_list = utils.get_bucket_metadata(s3_client, buket_name, prefix)\n",
    "    if metadata_list:\n",
    "        try:\n",
    "            _obj = metadata_list[0]\n",
    "            response = s3.get_object(Bucket=buket_name, Key=_obj['Key'])\n",
    "            json_context = response['Body'].read().decode('utf-8')\n",
    "            join_dict = json.loads(json_context)\n",
    "            return join_dict.get('ids')\n",
    "        except json.JSONDecodeError as e:\n",
    "            logging.error(f\"JSONDecodeError encountered: {e}\")\n",
    "            return False\n",
    "        except ClientError as e:\n",
    "            logging.error(f\"ClientError encountered: {e}\")\n",
    "            return False\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Unknow Error. encountered: {e}\")\n",
    "            return False\n",
    "        \n",
    "def remove_duplicate_id(s3_client, buket_name, _df):\n",
    "    id_list = get_id_from_s3(s3_client, buket_name, \"obj_ids.json\")\n",
    "    df_id_list = _df['id'].unique().tolist()\n",
    "    if id_list:\n",
    "        unput_id_list = [id for id in df_id_list if id not in id_list]\n",
    "        return unput_id_list\n",
    "    else:\n",
    "        return df_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 예시 데이터프레임 생성\n",
    "data = {\n",
    "    'id': [1, 2, 2, 3, 4, 4, 4, 5],\n",
    "    'name': ['Alice', 'Bob', 'Bob', 'Charlie', 'David', 'David', 'David', 'Eve']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 'id' 컬럼의 유니크 값만 추출\n",
    "unique_ids = df['id'].unique()\n",
    "\n",
    "print(unique_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = remove_duplicate_id(s3, id_list_bucket_name, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = put_id_to_s3(s3, id_list_bucket_name, \"obj_ids.json\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'FYQ7ECYMGTX39D5Z',\n",
       "  'HostId': '0nbyY78kkWhsZCaPK7vRwGcnwNtcnECZ1KKtKnIsa1SwC07sqZrLgJCgFB7POT7NHdkFFu/88HJW8f7GxPxg8Q==',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': '0nbyY78kkWhsZCaPK7vRwGcnwNtcnECZ1KKtKnIsa1SwC07sqZrLgJCgFB7POT7NHdkFFu/88HJW8f7GxPxg8Q==',\n",
       "   'x-amz-request-id': 'FYQ7ECYMGTX39D5Z',\n",
       "   'date': 'Wed, 04 Sep 2024 03:42:07 GMT',\n",
       "   'x-amz-server-side-encryption': 'AES256',\n",
       "   'etag': '\"19dd81bac54fc989ab08af0e1cfdb14d\"',\n",
       "   'server': 'AmazonS3',\n",
       "   'content-length': '0'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"19dd81bac54fc989ab08af0e1cfdb14d\"',\n",
       " 'ServerSideEncryption': 'AES256'}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
